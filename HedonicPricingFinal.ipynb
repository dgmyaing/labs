{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgmyaing/labs/blob/main/HedonicPricingFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-lkSnt44clOd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "#Importing anything I may need to use\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/DS3001/labs/refs/heads/main/04_hedonic_pricing/airbnb_hw.csv'\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/DS3001/labs/refs/heads/main/04_hedonic_pricing/airbnb_hw.csv'\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "print(\"Summary of Data:\")\n",
        "data.info()\n",
        "\n",
        "print(\"\\nFirst Few Rows:\")\n",
        "print(data.head())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(data.isnull().sum())\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "data.drop_duplicates(inplace=True) #Getting rid of duplication\n",
        "\n",
        "print(\"\\nData Stats Description:\")\n",
        "print(data.describe())\n",
        "\n",
        "# I feel like this should be a good enough introduction to most of the data present"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePVuUAoXgNCF",
        "outputId": "6192ecf4-9524-44e5-c5db-d0b772f01e09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary of Data:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30478 entries, 0 to 30477\n",
            "Data columns (total 13 columns):\n",
            " #   Column                      Non-Null Count  Dtype  \n",
            "---  ------                      --------------  -----  \n",
            " 0   Host Id                     30478 non-null  int64  \n",
            " 1   Host Since                  30475 non-null  object \n",
            " 2   Name                        30478 non-null  object \n",
            " 3   Neighbourhood               30478 non-null  object \n",
            " 4   Property Type               30475 non-null  object \n",
            " 5   Review Scores Rating (bin)  22155 non-null  float64\n",
            " 6   Room Type                   30478 non-null  object \n",
            " 7   Zipcode                     30344 non-null  float64\n",
            " 8   Beds                        30393 non-null  float64\n",
            " 9   Number of Records           30478 non-null  int64  \n",
            " 10  Number Of Reviews           30478 non-null  int64  \n",
            " 11  Price                       30478 non-null  object \n",
            " 12  Review Scores Rating        22155 non-null  float64\n",
            "dtypes: float64(4), int64(3), object(6)\n",
            "memory usage: 3.0+ MB\n",
            "\n",
            "First Few Rows:\n",
            "    Host Id Host Since                                Name Neighbourhood   \\\n",
            "0   5162530        NaN     1 Bedroom in Prime Williamsburg       Brooklyn   \n",
            "1  33134899        NaN     Sunny, Private room in Bushwick       Brooklyn   \n",
            "2  39608626        NaN                Sunny Room in Harlem      Manhattan   \n",
            "3       500  6/26/2008  Gorgeous 1 BR with Private Balcony      Manhattan   \n",
            "4       500  6/26/2008            Trendy Times Square Loft      Manhattan   \n",
            "\n",
            "  Property Type  Review Scores Rating (bin)        Room Type  Zipcode  Beds  \\\n",
            "0     Apartment                         NaN  Entire home/apt  11249.0   1.0   \n",
            "1     Apartment                         NaN     Private room  11206.0   1.0   \n",
            "2     Apartment                         NaN     Private room  10032.0   1.0   \n",
            "3     Apartment                         NaN  Entire home/apt  10024.0   3.0   \n",
            "4     Apartment                        95.0     Private room  10036.0   3.0   \n",
            "\n",
            "   Number of Records  Number Of Reviews Price  Review Scores Rating  \n",
            "0                  1                  0   145                   NaN  \n",
            "1                  1                  1    37                   NaN  \n",
            "2                  1                  1    28                   NaN  \n",
            "3                  1                  0   199                   NaN  \n",
            "4                  1                 39   549                  96.0  \n",
            "\n",
            "Missing Values:\n",
            "Host Id                          0\n",
            "Host Since                       3\n",
            "Name                             0\n",
            "Neighbourhood                    0\n",
            "Property Type                    3\n",
            "Review Scores Rating (bin)    8323\n",
            "Room Type                        0\n",
            "Zipcode                        134\n",
            "Beds                            85\n",
            "Number of Records                0\n",
            "Number Of Reviews                0\n",
            "Price                            0\n",
            "Review Scores Rating          8323\n",
            "dtype: int64\n",
            "\n",
            "Data Stats Description:\n",
            "            Host Id  Review Scores Rating (bin)       Zipcode          Beds  \\\n",
            "count  2.200700e+04                22007.000000  22007.000000  22007.000000   \n",
            "mean   1.104610e+07                   90.732949  10575.311037      1.556687   \n",
            "std    1.079848e+07                    9.069640    597.741247      1.043301   \n",
            "min    5.000000e+02                   20.000000   7105.000000      0.000000   \n",
            "25%    2.241260e+06                   85.000000  10016.000000      1.000000   \n",
            "50%    6.900870e+06                   90.000000  10044.000000      1.000000   \n",
            "75%    1.808596e+07                  100.000000  11216.000000      2.000000   \n",
            "max    4.272660e+07                  100.000000  11694.000000     16.000000   \n",
            "\n",
            "       Number of Records  Number Of Reviews  Review Scores Rating  \n",
            "count            22007.0       22007.000000          22007.000000  \n",
            "mean                 1.0          16.461490             91.987731  \n",
            "std                  0.0          24.231379              8.860796  \n",
            "min                  1.0           1.000000             20.000000  \n",
            "25%                  1.0           3.000000             89.000000  \n",
            "50%                  1.0           7.000000             94.000000  \n",
            "75%                  1.0          20.000000            100.000000  \n",
            "max                  1.0         257.000000            100.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = ['Property Type', 'Room Type', 'Beds', 'Number of Records', 'Number Of Reviews', 'Review Scores Rating']\n",
        "X = data[features]\n",
        "y = data['Price']\n",
        "\n",
        "#Adding relevant data points into a consolidated place"
      ],
      "metadata": {
        "id": "IsmmAIdAglym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting price into numeric datapoints\n",
        "data['Price'] = data['Price'].replace(',', '', regex=True).astype(float)\n",
        "X = data[features]\n",
        "y = data['Price']\n",
        "X = pd.get_dummies(X, columns=['Property Type', 'Room Type'], drop_first=True)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #80/20 test split\n",
        "\n",
        "simple_model = LinearRegression()\n",
        "simple_model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred_simple = simple_model.predict(X_train)\n",
        "y_test_pred_simple = simple_model.predict(X_test)\n",
        "\n",
        "\n",
        "rmse_train_simple = mean_squared_error(y_train, y_train_pred_simple, squared=False)\n",
        "rmse_test_simple = mean_squared_error(y_test, y_test_pred_simple, squared=False)\n",
        "r2_train_simple = r2_score(y_train, y_train_pred_simple)\n",
        "r2_test_simple = r2_score(y_test, y_test_pred_simple)\n",
        "#Getting the RMSE and R^2\n",
        "print(\"Results\")\n",
        "print(f\"Training RMSE: {rmse_train_simple:.2f}, Training R^2: {r2_train_simple:.2f}\")\n",
        "print(f\"Test RMSE: {rmse_test_simple:.2f}, Test R^2: {r2_test_simple:.2f}\")\n",
        "#unsure of why I'm getting the FutureWarning, can't figure out how to get past that"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxoQeb7fjP0V",
        "outputId": "f6ddf799-7c36-4f1a-b32c-b961fd37c9cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simple Model Results:\n",
            "Training RMSE: 130.69, Training R^2: 0.22\n",
            "Test RMSE: 133.11, Test R^2: 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train['Beds_Squared'] = X_train['Beds'] ** 2\n",
        "X_test['Beds_Squared'] = X_test['Beds'] ** 2\n",
        "\n",
        "complex_model = LinearRegression()\n",
        "complex_model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred_complex = complex_model.predict(X_train)\n",
        "y_test_pred_complex = complex_model.predict(X_test)\n",
        "\n",
        "rmse_train_complex = mean_squared_error(y_train, y_train_pred_complex, squared=False)\n",
        "rmse_test_complex = mean_squared_error(y_test, y_test_pred_complex, squared=False)\n",
        "r2_train_complex = r2_score(y_train, y_train_pred_complex)\n",
        "r2_test_complex = r2_score(y_test, y_test_pred_complex)\n",
        "\n",
        "print(\"\\nComplex Model Results:\")\n",
        "print(f\"Training RMSE: {rmse_train_complex:.2f}, Training R^2: {r2_train_complex:.2f}\")\n",
        "print(f\"Test RMSE: {rmse_test_complex:.2f}, Test R^2: {r2_test_complex:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPmiwPlfjp1R",
        "outputId": "4c566802-86b7-431d-cdda-d254c95571af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Complex Model Results:\n",
            "Training RMSE: 130.68, Training R^2: 0.22\n",
            "Test RMSE: 133.45, Test R^2: 0.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The R² values are pretty low—0.22 for training and 0.25 for testing—which means the models aren’t doing a great job of explaining the variance in Price. This suggests the models might be too basic to capture the relationships in the data, or we could be missing some important features. That said, since the training and test set performances are similar, there’s no obvious sign of overfitting. If the models were overfitting, we’d usually see much higher R² and lower RMSE for the training set compared to the test set."
      ],
      "metadata": {
        "id": "Nd5TkFjzqMc-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I started by exploring and cleaning the dataset to prepare it for regression analysis. This involved handling missing values, transforming categorical variables, and cleaning up numeric columns that had special characters like commas. My key takeaway from this step was that cleaning and preprocessing are essential to make the data usable, especially when working with a combination of numerical and categorical variables.\n",
        "\n",
        "After cleaning the data, I built a simple linear regression model without adding any transformations or interaction terms. The results showed a training RMSE of 130.69 and a training R² of 0.22, while the test RMSE was 133.11 and the test R² was 0.25. These low R² values indicated that the model couldn’t explain much of the variance in the target variable (price), which suggested it was underfitting. The simplicity of the model likely prevented it from capturing the complexity of the data.\n",
        "\n",
        "To improve the model, I constructed a more complex version by including interaction terms and transformations to better capture relationships between features. However, the results were nearly identical to the simple model: a training RMSE of 130.68, training R² of 0.22, test RMSE of 133.45, and test R² of 0.25. This showed that the added complexity didn’t improve the model’s performance, meaning the additional terms failed to uncover any new patterns. The model still appeared to be underfitting.\n",
        "\n",
        "When comparing the two models, I noticed their similar performance on both the training and test sets. This ruled out overfitting since an overfit model would have performed much better on the training set than the test set. The low R² values for both models confirmed that underfitting was the real issue, likely due to missing key predictors or insufficient feature engineering.\n",
        "\n",
        "To address this, I considered using a Lasso regression model. Lasso regularization could help identify the most important features by shrinking less relevant ones to zero, which would improve interpretability and reduce noise. While regularization could help prevent overfitting, I realized it wouldn’t fully resolve the underfitting problem if critical features were missing. This emphasized the need for careful feature selection and engineering in addition to model tuning.\n"
      ],
      "metadata": {
        "id": "tvnYPyBaqCBW"
      }
    }
  ]
}